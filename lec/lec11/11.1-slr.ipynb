{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f8e679",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\" id=\"nb-header\">\n",
    "    <tr style=\"background-color: transparent;\"><td>\n",
    "        <img src=\"https://data-88e.github.io/assets/images/blue_text.png\" width=\"250px\" style=\"margin-left: 0;\" />\n",
    "    </td><td>\n",
    "        <p style=\"text-align: right; font-size: 10pt;\"><strong>Economic Models</strong>, Fall 24<br>\n",
    "            Dr. Eric Van Dusen <br>\n",
    "            Vaidehi Bulusu <br>\n",
    "        <br>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d33dd-ff47-47c4-a69c-6a238b212d31",
   "metadata": {},
   "source": [
    "# Lecture Notebook 11.1: Simple Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from datascience import *\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf53bd",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "\n",
    "Let's learn about simple linear regression using a dataset you're already familiar with from week 2: the dataset on the price and quantity demanded of avocados. Recall that in week 2, we used `np.polyfit()` to find the slope and intercept. Here, we'll use regression to calculate the slope and intercept from scratch and get the same results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93808b2e",
   "metadata": {},
   "source": [
    "Go over this lecture notebook along with the slides!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a9e6c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "av_df = Table.read_table(\"avocados.csv\")\n",
    "av_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee731dbc",
   "metadata": {},
   "source": [
    "## Scatter Plot\n",
    "\n",
    "To investigate the relationship between price and quantity demanded, we can start by creating a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40420852",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_df.scatter(\"Average Price\", \"Total Volume\")\n",
    "plt.ylabel(\"Quantity Demanded\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.title(\"Demand Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9ad6a3",
   "metadata": {},
   "source": [
    "By looking at the scatter plot, we get a sense that there's a somewhat strong negative relationship between price and quantity demanded. Notice that the points don't all lie on a straight line as it's not a perfect association. This is because there is some random variation in the data plus there are factors other than price that affect the quantity demanded (we'll talk more about this later)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8cef9",
   "metadata": {},
   "source": [
    "## Correlation Coefficient\n",
    "\n",
    "To quantify the association and give it a numerical value, we can calculate the correlation coefficient between price and quantity demanded. Recall from DATA 8 that the correlation coefficient only measures **linear** association so for the purpose of this class, we are assuming that the relationship between the price and quantity demanded of avocados is linear (in reality, it may be nonlinear).\n",
    "\n",
    "Let's start by defining a function to calculate the correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes that array_x and array_y are in standard units\n",
    "def correlation(array_x, array_y):\n",
    "    return np.mean(array_x * array_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16322ca1",
   "metadata": {},
   "source": [
    "The first step in calculating the correlation coefficient is converting the data to standard units. When you express a value in standard units, you are basically standardizing the variable by expressing it in terms of the number of standard deviations it is above or below the mean (you can think of this as the \"distance\" from the mean). For example, the first value of the price shown below is around 1.2 standard deviations below the mean price.\n",
    "\n",
    "Expressing the data in standard units removes the measured units (e.g. dollars) from the data. So, the correlation coefficient is not affected by a change in the units/scale (e.g. if you convert the prices from USD to CAD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressing price in standard units\n",
    "price_su = (av_df[\"Average Price\"] - np.mean(av_df[\"Average Price\"]))/np.std(av_df[\"Average Price\"])\n",
    "price_su[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressing quantity in standard units\n",
    "quantity_su = (av_df[\"Total Volume\"] - np.mean(av_df[\"Total Volume\"]))/np.std(av_df[\"Total Volume\"])\n",
    "quantity_su[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7402185",
   "metadata": {},
   "source": [
    "Now we can use the function we defined to calculate the correlation coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = correlation(price_su, quantity_su)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9943db5d",
   "metadata": {},
   "source": [
    "As we expected, there is a pretty strong negative correlation between price and demand! It aligns with what we saw in the scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29dfba",
   "metadata": {},
   "source": [
    "## Regression Equation\n",
    "\n",
    "Let's use the correlation coefficient to build the regression equation. The first step is to calculate the slope and intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = r * np.std(av_df[\"Total Volume\"])/np.std(av_df[\"Average Price\"])\n",
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e8d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = np.mean(av_df[\"Total Volume\"]) - (slope * np.mean(av_df[\"Average Price\"]))\n",
    "intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a4976",
   "metadata": {},
   "source": [
    "We can now write the regression equation for the relationship between price and quantity demanded.\n",
    "\n",
    "$$\\hat{quantity} = 1446951.641 -476412.719\\hat{price}$$\n",
    "\n",
    "This equation allows you to do 2 things:\n",
    "\n",
    "- Quantify the association between price and quantity demanded: as price increases by $1, the quantity demanded decreases by around 476,000 units (avocados)\n",
    "\n",
    "\n",
    "- Predict values of quantity demanded: this is especially useful for values of price that are not already in the dataset\n",
    "\n",
    "Note that the regression line is the line of best fit for your data (more on this later). We can plot this line of best fit on the scatter plot from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_df.scatter(\"Average Price\", \"Total Volume\")\n",
    "plt.plot(av_df[\"Average Price\"], slope * av_df[\"Average Price\"] + intercept, color='tab:orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94a5d3",
   "metadata": {},
   "source": [
    "Does this graph look familiar? You've already done a similar analysis in week 2 when you used `np.polyfit` to find the slope and intercept of the line of best fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.polyfit(av_df[\"Average Price\"], av_df[\"Total Volume\"], 1)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72b4e6",
   "metadata": {},
   "source": [
    "The slope and intercept you get from `np.polyfit` should be very close to the slope and intercept from before (there might be some tiny variation). This is because under the hood, np.polyfit is using simple linear regression to calculate the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param = params[0]\n",
    "np.round(slope_param, 5) == np.round(slope, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_param = params[1]\n",
    "np.round(intercept_param, 5) == np.round(intercept, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960baa5",
   "metadata": {},
   "source": [
    "## RMSE\n",
    "\n",
    "Let's use the slope and intercept to generate predictions for the quantity demanded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd98041",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_quantity = intercept + (slope * av_df[\"Average Price\"])\n",
    "predicted_quantity[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d9f2a",
   "metadata": {},
   "source": [
    "We want our predictions to be as accurate as possible. One metric we can use to measure the accuracy of our predictions is the root mean squared error (RMSE) which gives us a sense of how far our predictions are from the actual values, on average.\n",
    "\n",
    "Let's define a function for calculating the RMSE of our data (note that this function is specific to the avocados dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_p_q(slope, intercept):\n",
    "    predicted_y = intercept + (slope * av_df[\"Average Price\"])\n",
    "    return (np.mean((av_df[\"Total Volume\"] - predicted_y)**2))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bfb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_1 = rmse_p_q(slope, intercept)\n",
    "rmse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7cbd68",
   "metadata": {},
   "source": [
    "On average, our predictions are off by about $132,000. This is a pretty high RMSE! This shows that even though price and quantity demanded have a pretty high correlation (about 0.72), it doesn't necessarily mean that price is a good predictor for the quantity demanded.\n",
    "\n",
    "We said earlier that the regression line is the line of best fit. The reason why is that the regression line minimizes the RMSE of your data. In other words, among all the lines you can use to model your data, the regression line is the one that is the most accurate as it minimizes RMSE – this is why this technique is called (ordinary) least squares regression.\n",
    "\n",
    "We can test this using the minimize function. Recall that minimize takes a function as the input as gives you values of the arguments of that function that minimize it. Below, we would expect the output of the minimize function to be similar to the slope and intercept we calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93557e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = minimize(rmse_p_q)\n",
    "minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f66b8",
   "metadata": {},
   "source": [
    "The slope and intercept from the minimize function is very similar to the slope and intercept we calculated, as expected!\n",
    "\n",
    "When you perform regression in Python (e.g. when you use `np.polyfit`), it tries to find the values of the slope and intercept that minimize the RMSE. You can build your intuition for how it does this by playing around with this slider from [last semester's notebook](https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fdata-88e%2Fecon-sp21&urlpath=tree%2Fecon-sp21%2Flec%2Flec12%2Flec12.ipynb&branch=main) (you can also find the link in on last semester's [website](https://data-88e.github.io/sp21/), in econometrics week). See if you can find values for the slope and intercept that minimize the squared error area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d14236",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Table().with_columns(\n",
    "    'x', make_array(0,  1,  2,  3,  4),\n",
    "    'y', make_array(1, .5, -1,  2, -3))\n",
    "\n",
    "def rmse(target, pred):\n",
    "    return np.sqrt(mean_squared_error(target, pred))\n",
    "\n",
    "def plot_line_and_errors(slope, intercept):\n",
    "    print(\"RMSE:\", rmse(slope * d.column('x') + intercept, d.column('y')))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    points = make_array(-2, 7)\n",
    "    p = plt.plot(points, slope*points + intercept, color='orange', label='Proposed line')\n",
    "    ax = p[0].axes\n",
    "    \n",
    "    predicted_ys = slope*d.column('x') + intercept\n",
    "    diffs = predicted_ys - d.column('y')\n",
    "    for i in np.arange(d.num_rows):\n",
    "        x = d.column('x').item(i)\n",
    "        y = d.column('y').item(i)\n",
    "        diff = diffs.item(i)\n",
    "        \n",
    "        if diff > 0:\n",
    "            bottom_left_x = x\n",
    "            bottom_left_y = y\n",
    "        else:\n",
    "            bottom_left_x = x + diff\n",
    "            bottom_left_y = y + diff\n",
    "        \n",
    "        ax.add_patch(patches.Rectangle(make_array(bottom_left_x, bottom_left_y), abs(diff), abs(diff), color='red', alpha=.3, label=('Squared error' if i == 0 else None)))\n",
    "        plt.plot(make_array(x, x), make_array(y, y + diff), color='red', alpha=.6, label=('Error' if i == 0 else None))\n",
    "    \n",
    "    plt.scatter(d.column('x'), d.column('y'), color='blue', label='Points')\n",
    "    \n",
    "    plt.xlim(-4, 8)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.8, .8))\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_line_and_errors, slope=widgets.FloatSlider(min=-4, max=4, step=.1), intercept=widgets.FloatSlider(min=-4, max=4, step=.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58585c48",
   "metadata": {},
   "source": [
    "## Regression in Python\n",
    "\n",
    "So far, we've looked at the DATA 8 version of regression in which we calculated the correlated coefficient and used it to find the slope and intercept of our regression line.\n",
    "\n",
    "Now we can look at how regression is actually performed in Python using a library called `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm – see first cell in the notebook\n",
    "x_1 = av_df.column(\"Average Price\") # Selecting the independent variable(s)\n",
    "y_1 = av_df.column(\"Total Volume\") # Selecting the dependent variable\n",
    "model_1 = sm.OLS(y_1, sm.add_constant(x_1)) # Performing OLS regression – make sure to include intercept using sm.add_constant\n",
    "result_1 = model_1.fit() # Fitting the model\n",
    "result_1.summary() # Showing a summary of the results of the regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a1d3a",
   "metadata": {},
   "source": [
    "Let's look at the parameters (slope and intercept) of the regression and see if they are close to the parameters we calculated before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f60dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result_1.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(result_1.params[0], 5) == np.round(intercept, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335d218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.round(result_1.params[1], 5) == np.round(slope, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46181ae3",
   "metadata": {},
   "source": [
    "They are similar, as we expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0fcc4c",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Since we are interested in whether or not there is a substantial association between x and y (in this case, price and quantity demanded), we can frame this as a hypothesis testing question:\n",
    "\n",
    "- The null hypothesis would be that there isn't a substantial association between x and y ($\\beta = 0$)\n",
    "\n",
    "- The alternative hypothesis would be that there is a substantial association between x and y ($\\beta ≠ 0$)\n",
    "\n",
    "Go back to the regression output from before: notice that it shows a 95% confidence interval for the slope. Let's try to visualize this confidence interval by creating a distribution of the regression slopes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee9056f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slopes_array = make_array()\n",
    "for i in np.arange(5000):\n",
    "    bootstrapped_sample = av_df.select(\"Average Price\", \"Total Volume\").sample()\n",
    "    x = bootstrapped_sample.column(\"Average Price\")\n",
    "    y = bootstrapped_sample.column(\"Total Volume\")\n",
    "    results = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    slopes_array = np.append(results.params[1], slopes_array)\n",
    "Table().with_column(\"Slopes\", slopes_array).hist()\n",
    "print(\"Center of the distribution (mean):\", np.mean(slopes_array))\n",
    "print(\"Standard deviation:\", np.std(slopes_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb068965",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_lower_bound = percentile(2.5, slopes_array)\n",
    "ci_lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6ba1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ci_upper_bound = percentile(97.5, slopes_array)\n",
    "ci_upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf99336",
   "metadata": {},
   "source": [
    "Notice that the center of the distribution (average of the slopes) is similar to the slope from the regression output. The lower and upper bounds of the confidence interval are also similar.\n",
    "\n",
    "Recall that if the confidence interval contains 0, it means that there is evidence for the null hypothesis at the 5% significance level. If it doesn't contain 0, it means that there is evidence against the null hypothesis at the 5% level.\n",
    "\n",
    "The confidence interval in the regression output above doesn't contain 0 so there's evidence that price and quantity demanded have a significant association. This makes sense as they have a relatively high correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b0970-5cdb-4611-8eca-6fff908779c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
